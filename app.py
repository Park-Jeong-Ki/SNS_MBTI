from langchain.chains import SequentialChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import ChatPromptTemplate
from langchain.chains import LLMChain
import streamlit as st
import os
from langchain.callbacks import get_openai_callback
import re
import requests
import joblib
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer

# ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì„¤ì •
IMAGE_DIR = 'images'

# MBTI ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
def display_mbti_images():
    # ì´ë¯¸ì§€ ê²½ë¡œì™€ ìº¡ì…˜ ì •ì˜
    mbti_types = [
        'ENFJ', 'ENFP', 'ENTJ', 'ENTP',
        'ESFJ', 'ESFP', 'ESTJ', 'ESTP',
        'INFJ', 'INFP', 'INTJ', 'INTP',
        'ISFJ', 'ISFP', 'ISTJ', 'ISTP'
    ]

    # ì´ë¯¸ì§€ë¥¼ ë‹´ì„ ì»¨í…Œì´ë„ˆ ìƒì„±
    with st.container():
        # ì´ë¯¸ì§€ë¥¼ ë‘ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ
        cols = st.columns(2)
        for index, mbti_type in enumerate(mbti_types):
            file_path = f'./{IMAGE_DIR}/{mbti_type}_unique_words.png'
            if os.path.isfile(file_path):
                # í•´ë‹¹ ì»¬ëŸ¼ì— ì´ë¯¸ì§€ í‘œì‹œ
                with cols[index % 2]:
                    st.image(file_path, caption=f'{mbti_type} Unique Words', use_column_width=True)


def preprocess_text(text):
    # ì†Œë¬¸ì ë³€í™˜
    text = text.lower()

    # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)

    # í† í°í™” (ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬)
    tokens = word_tokenize(text)

    # ë¶ˆìš©ì–´ ì œê±°
    filtered_tokens = [word for word in tokens if word not in stop_words]

    # ì •ì œëœ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ì¬ê²°í•©
    text = ' '.join(filtered_tokens)

    return text

def translate_EN(content, api_key):
    response = requests.post(
        "https://api-free.deepl.com/v2/translate",
        data={
            "auth_key": api_key,
            "text": content,
            "target_lang": "EN",
        }
    )
    response.raise_for_status()
    return response.json()["translations"][0]["text"]

def translate_KO(content, api_key):
    response = requests.post(
        "https://api-free.deepl.com/v2/translate",
        data={
            "auth_key": api_key,
            "text": content,
            "target_lang": "KO",
        }
    )
    response.raise_for_status()
    return response.json()["translations"][0]["text"]

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SNS MBTI: ë””ì§€í„¸ í˜ë¥´ì†Œë‚˜ ë¶„ì„", layout="wide")


api_key = st.sidebar.text_input('OpenAI API Key', type='password')
st.sidebar.info("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. API í‚¤ê°€ ì—†ë‹¤ë©´ [OpenAI](https://beta.openai.com/)ì—ì„œ ê³„ì •ì„ ìƒì„±í•˜ê³  API í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
os.environ['OPENAI_API_KEY'] = api_key
if api_key:

    llm = ChatOpenAI(temperature=0.8, model="gpt-4")


    # 1. input ê°’ ìš”ì•½í•˜ê¸°
    first_prompt = ChatPromptTemplate.from_template(
        "Summarize the content:"
        "\n\n{Content}"
    )
    chain_one = LLMChain(llm=llm, prompt=first_prompt,
                        output_key="summary"
                        )


    # 2. ê°ì •ìƒíƒœ ì´ëª¨ì§€ë¡œ í‘œí˜„í•˜ê¸°
    second_prompt = ChatPromptTemplate.from_template(
        "Chose one of the emogis in the Emogi that repersent writer's sentiment"
        "\n\n{summary}"
    )
    chain_two = LLMChain(llm=llm, prompt=second_prompt,
                        output_key="sentiment"
                        )

    # 3. MBTI ì¶”ì¸¡í•˜ê¸°
    third_prompt = ChatPromptTemplate.from_template(
        "Choose one of the full MBTI types that represents a writer. Briefly describe the MBTI type you selected. And then logically explain why you think so."
        "\n\n{summary}"
    )
    chain_three = LLMChain(llm=llm, prompt=third_prompt,
                        output_key="mbti"
                        )



    # 1,2,3ë²ˆ ì²´ì¸ì„ ë¬¶ìŒ
    overall_chain = SequentialChain(
        chains=[chain_one, chain_two, chain_three],
        input_variables=["Content"],
        output_variables=["summary", "sentiment", "mbti"],
    )

# ì´ë¯¸ì§€ ì¶”ê°€ (ê²½ë¡œë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë°”ê¿”ì£¼ì„¸ìš”)


st.title("SNS MBTI: ë””ì§€í„¸ í˜ë¥´ì†Œë‚˜ ë¶„ì„ ğŸŒŸ")

# ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë¡œ ë°°ì¹˜
col1, col2 = st.columns(2)
with col1:
    st.image('./1.png', caption='ë©€í‹° í˜ë¥´ì†Œë‚˜')

with col2:
    st.image('./2.png', caption='ë©€í‹° í˜ë¥´ì†Œë‚˜')

st.subheader("SNSì—ì„œ ì–´ë–¤ MBTI ìœ í˜•ìœ¼ë¡œ ë¹„ì¶°ì§€ëŠ”ì§€ ê¶ê¸ˆí•˜ì‹œì§€ëŠ” ì•Šìœ¼ì‹ ê°€ìš”? ğŸ’­\n")
st.text("ì´ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ì„œ ìì‹  í˜¹ì€ íƒ€ì¸ì˜ ì˜¨ë¼ì¸ ìƒ í–‰ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ìˆ¨ê²¨ì§„ MBTI ìœ í˜•ì„ íƒìƒ‰í•´ë³´ì„¸ìš”. ğŸ•µï¸â€â™‚ï¸ğŸ•µï¸â€â™€ï¸\nGPT-4ì™€ 10ë§Œê°œì´ìƒì˜ ë°ì´í„° ë¶„ì„ì„ í†µí•´, ê·¸ë“¤ì´ SNSì— ë‚¨ê¸´ ê¸€ê³¼ í™œë™ì—ì„œ ë¹„ì¶°ì§€ëŠ” ì„±ê²© íŠ¹ì„±ì„ íŒŒì•…í•©ë‹ˆë‹¤.\në‹¨ìˆœí•œ MBTI í…ŒìŠ¤íŠ¸ë¥¼ ë„˜ì–´ì„œ, íƒ€ì¸ì˜ ë””ì§€í„¸ ì„¸ê³„ ì† ë‹¤ì–‘í•œ ë©´ëª¨ë¥¼ ë°œê²¬í•˜ë©°, ìƒˆë¡œìš´ ê´€ì ìœ¼ë¡œ ê·¸ë“¤ì„ ì´í•´í•´ ë³´ì„¸ìš”. ğŸŒğŸ‘€")

st.text("\n\n")

Content = st.text_area("ë””ì§€í„¸ í˜ë¥´ì†Œë‚˜ MBTI ë¶„ì„ì„ ìœ„í•´ ì‘ì„±í•œ ë³¸ì¸, í˜¹ì€ íƒ€ì¸ì˜ ê¸€(SNS, ì¹´í†¡, ë¸”ë¡œê·¸)ì„ ì˜¬ë ¤ì£¼ì„¸ìš”! ğŸ“", height=200, max_chars=2000, placeholder="ê¸€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ìµœëŒ€ 2000ì)")

# "MBTI ê·¸ë˜í”„ ë³´ê¸°" ë²„íŠ¼ ì¶”ê°€
if st.button("MBTI ê·¸ë˜í”„ ë³´ê¸°"):
    display_mbti_images()

if st.button('ë””ì§€í„¸ í˜ë¥´ì†Œë‚˜ MBTI ì˜ˆì¸¡í•´ë³´ê¸°'):
    if not api_key:
        st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    if not Content:
        st.error("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else :
        with st.spinner('ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                with get_openai_callback() as cb:
                    result = overall_chain(Content, return_only_outputs=True)

                api_key = "08c7454a-642e-f493-4893-50e3e8046254:fx"

                summary = result['summary']
                summary = translate_KO(summary, api_key)
                sentiment = result['sentiment']
                mbti = result['mbti']
                mbti = translate_KO(mbti, api_key)

                # ì •ê·œ í‘œí˜„ì‹ì„ ì´ìš©í•˜ì—¬ ì²˜ìŒìœ¼ë¡œ ë‚˜ì˜¤ëŠ” MBTI ìœ í˜•ì„ ì°¾ìŒ
                mbti_types = ["ISTJ", "ISFJ", "INFJ", "INTJ", "ISTP", "ISFP", "INFP", "INTP",
                            "ESTP", "ESFP", "ENFP", "ENTP", "ESTJ", "ESFJ", "ENFJ", "ENTJ"]

                pattern = r"\b(" + "|".join(mbti_types) + r")\b"
                mbti_result = re.search(pattern, mbti, re.IGNORECASE)

                st.subheader('ìš”ì•½')
                st.write(summary)
                st.divider()
                st.subheader('GPTì˜ ì˜ˆì¸¡ :blue[MBTI]:')

                # ì°¾ì€ MBTI ê²°ê³¼ë¥¼ ì €ì¥
                if mbti_result:
                    extracted_mbti = mbti_result.group(1).upper()  # ëŒ€ë¬¸ìë¡œ ë³€í™˜
                    st.header(extracted_mbti)
                    st.write(mbti)
                else:
                    st.write(mbti)
                st.divider()
                st.subheader(':blue[í˜„ì¬ ê¸°ë¶„]:')
                st.title(sentiment)
                st.divider()
                st.info(cb)

                # NLTK ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë¶ˆìš©ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                nltk.download('punkt')
                nltk.download('stopwords')

                # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
                stop_words = set(stopwords.words('english'))


                en_content = translate_EN(Content, api_key)

                model = joblib.load('mbti_model_2.joblib')
                tfidf_vectorizer = joblib.load('tfidf_vectorizer.joblib')

                # ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ëª¨ë¸ì„ í†µí•œ MBTI ì˜ˆì¸¡
                processed_text = preprocess_text(Content)
                vectorized_text = tfidf_vectorizer.transform([processed_text])
                predicted_mbti = model.predict(vectorized_text)

                st.divider()
                st.subheader('ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ ì˜ˆì¸¡ :blue[MBTI]:')
                st.write("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•œ í›„, TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n"
                         "ì˜ˆì¸¡ ê²°ê³¼ëŠ” ë¶€ì •í™• í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ¤”\n")
                st.header(predicted_mbti[0])

                st.success('ì˜ˆì¸¡ ì™„ë£Œ!')


            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
