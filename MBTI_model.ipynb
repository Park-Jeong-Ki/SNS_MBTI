{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000db239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오버샘플링 전 학습 데이터 클래스 분포:\n",
      "INTP    22448\n",
      "INTJ    20126\n",
      "INFJ    13493\n",
      "INFP    10938\n",
      "ENTP    10558\n",
      "ENFP     5522\n",
      "ISTP     3105\n",
      "ENTJ     2677\n",
      "ESTP     1795\n",
      "ENFJ     1364\n",
      "ISTJ     1126\n",
      "ISFP      806\n",
      "ISFJ      582\n",
      "ESTJ      432\n",
      "ESFP      322\n",
      "ESFJ      166\n",
      "Name: type, dtype: int64\n",
      "\n",
      "오버샘플링 후 학습 데이터 클래스 분포:\n",
      "INTP    22448\n",
      "INFP    22448\n",
      "ENFP    22448\n",
      "ISTP    22448\n",
      "INFJ    22448\n",
      "ISTJ    22448\n",
      "INTJ    22448\n",
      "ENTP    22448\n",
      "ESTP    22448\n",
      "ENTJ    22448\n",
      "ISFJ    22448\n",
      "ENFJ    22448\n",
      "ISFP    22448\n",
      "ESFP    22448\n",
      "ESTJ    22448\n",
      "ESFJ    22448\n",
      "Name: type, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.40      0.71      0.51       170\n",
      "        ENFP       0.55      0.73      0.62       645\n",
      "        ENTJ       0.70      0.78      0.74       278\n",
      "        ENTP       0.73      0.69      0.71      1167\n",
      "        ESFJ       0.32      0.40      0.35        15\n",
      "        ESFP       0.28      0.50      0.36        38\n",
      "        ESTJ       0.81      0.78      0.80        50\n",
      "        ESTP       0.63      0.88      0.73       191\n",
      "        INFJ       0.71      0.67      0.69      1470\n",
      "        INFP       0.68      0.67      0.67      1196\n",
      "        INTJ       0.80      0.64      0.71      2301\n",
      "        INTP       0.78      0.67      0.72      2513\n",
      "        ISFJ       0.32      0.68      0.43        68\n",
      "        ISFP       0.20      0.71      0.31        69\n",
      "        ISTJ       0.35      0.79      0.48       117\n",
      "        ISTP       0.54      0.68      0.60       319\n",
      "\n",
      "    accuracy                           0.68     10607\n",
      "   macro avg       0.55      0.69      0.59     10607\n",
      "weighted avg       0.71      0.68      0.69     10607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# 데이터 로딩\n",
    "mbti_data = pd.read_csv('./MBTI 500.csv')\n",
    "\n",
    "# NLTK 라이브러리의 불용어 데이터 다운로드\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 불용어 리스트\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 소문자 변환\n",
    "    text = text.lower()\n",
    "\n",
    "    # 특수 문자 제거\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # 토큰화 (단어 단위로 분리)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 불용어 제거\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 정제된 텍스트를 문자열로 재결합\n",
    "    text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 모든 게시물에 대해 전처리 수행\n",
    "mbti_data['posts'] = mbti_data['posts'].apply(preprocess_text)\n",
    "# TF-IDF 계산\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(mbti_data['posts'])\n",
    "\n",
    "# TF-IDF 벡터라이저 저장\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "y = mbti_data['type']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 오버샘플링을 위한 인스턴스 생성\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# 오버샘플링 전 학습 데이터의 클래스 분포 확인\n",
    "print(\"오버샘플링 전 학습 데이터 클래스 분포:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# 오버샘플링 적용\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 오버샘플링 후 학습 데이터의 클래스 분포 확인\n",
    "print(\"\\n오버샘플링 후 학습 데이터 클래스 분포:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# 모델 학습\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90449854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mbti_model.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 학습된 모델을 파일로 저장\n",
    "model_filename = 'mbti_model.joblib'\n",
    "joblib.dump(model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5f7dd",
   "metadata": {},
   "source": [
    "## 개별 MBTI 유형별 분석\n",
    "\n",
    "Precision은 모델이 해당 유형이라고 예측한 경우 중 실제로 해당 유형인 비율입니다.\n",
    "ESTJ (0.81), INTJ (0.80), INTP (0.78), ENTP (0.73), INFJ (0.71) 유형에서 상대적으로 높은 Precision 값을 보입니다. 이는 이러한 유형에 대한 예측이 정확하다는 것을 나타냅니다.\n",
    "Recall:\n",
    "\n",
    "Recall은 실제 해당 유형인 경우 중 모델이 올바르게 예측한 비율입니다.\n",
    "ESTP (0.88), ISTJ (0.79), ENTJ (0.78), ENFP (0.73), ESFP (0.50) 유형에서 상대적으로 높은 Recall 값을 보입니다. 이는 이러한 유형을 잘 감지한다는 것을 의미합니다.\n",
    "F1-Score:\n",
    "\n",
    "F1-Score는 Precision과 Recall의 조화 평균으로, 두 지표의 균형을 나타냅니다.\n",
    "ESTJ (0.80), ENTJ (0.74), ESTP (0.73), ENTP (0.71), INTP (0.72) 유형이 높은 F1-Score를 보이며, 이는 균형 잡힌 예측 성능을 나타냅니다.\n",
    "전체적인 모델 성능\n",
    "Accuracy: 전체 데이터 중 모델이 올바르게 예측한 비율은 0.68(68%)입니다. 이는 전체적으로 괜찮은 성능을 나타냅니다.\n",
    "Macro Avg: 모든 클래스에 대한 평균 Precision, Recall, F1-Score 입니다. 여기서는 각각 0.55, 0.69, 0.59로 나타났습니다. 특히 Recall이 높게 나온 것은 모델이 다양한 유형을 잘 감지하지만, 실제로 그 유형이 아닌 경우에도 자주 그 유형으로 분류한다는 것을 의미할 수 있습니다.\n",
    "Weighted Avg: 클래스의 샘플 크기를 고려한 가중 평균 성능입니다. Precision, Recall, F1-Score가 각각 0.71, 0.68, 0.69로 나타났습니다. 이는 데이터셋의 불균형을 고려한 평균 성능을 나타내며, 전반적으로 균형 잡힌 성능을 보여줍니다.\n",
    "\n",
    "\n",
    "해석\n",
    "이 결과는 모델이 특정 MBTI 유형에 대해 잘 예측하는 경향이 있으며, 특히 일부 유형에서 높은 정확도를 보임을 나타냅니다. 그러나 일부 유형에서 낮은 Precision이나 Recall 값을 보여, 이 유형에 대한 예측 개선이 필요함을 나타냅니다. 또한, 전체적인 성능 지표는 모델이 균형 잡힌 예측을 하고 있음을 보여줍니다. 하지만 여전히 개선의 여지가 있으며,특히 소수 클래스에 대한 예측력을 향상시키기 위한 방법을 고려할 필요가 있습니다. 소수 클래스의 경우, 낮은 Precision과 Recall 값이 나타나는 경향이 있으므로, 이러한 유형들에 대한 예측 정확도를 개선하는 것이 중요합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38013d4c",
   "metadata": {},
   "source": [
    "## 모델의 성능을 높히기 위해서 LinearSVC 모델로 한번 더 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a91e6723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오버샘플링 전 학습 데이터 클래스 분포:\n",
      "INTP    22448\n",
      "INTJ    20126\n",
      "INFJ    13493\n",
      "INFP    10938\n",
      "ENTP    10558\n",
      "ENFP     5522\n",
      "ISTP     3105\n",
      "ENTJ     2677\n",
      "ESTP     1795\n",
      "ENFJ     1364\n",
      "ISTJ     1126\n",
      "ISFP      806\n",
      "ISFJ      582\n",
      "ESTJ      432\n",
      "ESFP      322\n",
      "ESFJ      166\n",
      "Name: type, dtype: int64\n",
      "\n",
      "오버샘플링 후 학습 데이터 클래스 분포:\n",
      "INTP    22448\n",
      "INFP    22448\n",
      "ENFP    22448\n",
      "ISTP    22448\n",
      "INFJ    22448\n",
      "ISTJ    22448\n",
      "INTJ    22448\n",
      "ENTP    22448\n",
      "ESTP    22448\n",
      "ENTJ    22448\n",
      "ISFJ    22448\n",
      "ENFJ    22448\n",
      "ISFP    22448\n",
      "ESFP    22448\n",
      "ESTJ    22448\n",
      "ESFJ    22448\n",
      "Name: type, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.59      0.71      0.64       170\n",
      "        ENFP       0.69      0.78      0.73       645\n",
      "        ENTJ       0.66      0.84      0.74       278\n",
      "        ENTP       0.79      0.81      0.80      1167\n",
      "        ESFJ       0.38      0.53      0.44        15\n",
      "        ESFP       0.60      0.55      0.58        38\n",
      "        ESTJ       0.71      0.90      0.80        50\n",
      "        ESTP       0.85      0.90      0.87       191\n",
      "        INFJ       0.80      0.78      0.79      1470\n",
      "        INFP       0.76      0.77      0.77      1196\n",
      "        INTJ       0.84      0.79      0.81      2301\n",
      "        INTP       0.86      0.78      0.82      2513\n",
      "        ISFJ       0.67      0.72      0.70        68\n",
      "        ISFP       0.46      0.67      0.55        69\n",
      "        ISTJ       0.55      0.73      0.62       117\n",
      "        ISTP       0.70      0.80      0.75       319\n",
      "\n",
      "    accuracy                           0.79     10607\n",
      "   macro avg       0.68      0.75      0.71     10607\n",
      "weighted avg       0.79      0.79      0.79     10607\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mbti_model_2.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "\n",
    "# 데이터 로딩\n",
    "mbti_data = pd.read_csv('./MBTI 500.csv')\n",
    "\n",
    "# NLTK 라이브러리의 불용어 데이터 다운로드\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 불용어 리스트\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 소문자 변환\n",
    "    text = text.lower()\n",
    "\n",
    "    # 특수 문자 제거\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # 토큰화 (단어 단위로 분리)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 불용어 제거\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 정제된 텍스트를 문자열로 재결합\n",
    "    text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 모든 게시물에 대해 전처리 수행\n",
    "mbti_data['posts'] = mbti_data['posts'].apply(preprocess_text)\n",
    "# TF-IDF 계산\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(mbti_data['posts'])\n",
    "\n",
    "# TF-IDF 벡터라이저 저장\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "y = mbti_data['type']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 오버샘플링을 위한 인스턴스 생성\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# 오버샘플링 전 학습 데이터의 클래스 분포 확인\n",
    "print(\"오버샘플링 전 학습 데이터 클래스 분포:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# 오버샘플링 적용\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 오버샘플링 후 학습 데이터의 클래스 분포 확인\n",
    "print(\"\\n오버샘플링 후 학습 데이터 클래스 분포:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# 모델 학습\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 학습된 모델을 파일로 저장\n",
    "model_filename = 'mbti_model_2.joblib'\n",
    "joblib.dump(model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c87a55",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes (MultinomialNB):\n",
    "\n",
    "이 모델은 텍스트 데이터와 같은 이산적 특징에 잘 작동하는 확률 기반의 분류기입니다.\n",
    "Naive Bayes 분류기는 특징 간의 독립성을 가정합니다. 즉, 한 특징이 주어졌을 때 다른 특징들의 영향을 받지 않는다고 가정합니다.\n",
    "작은 데이터셋에도 잘 작동하지만, 복잡한 패턴이나 특징 간의 상호작용을 모델링하는 데는 제한적일 수 있습니다.\n",
    "이 분류기는 각 클래스에 대한 사전 확률을 기반으로 하며, 데이터의 분포가 각 클래스의 사전 확률과 얼마나 일치하는지에 따라 예측을 합니다.\n",
    "\n",
    "## Linear Support Vector Classification (LinearSVC):\n",
    "\n",
    "이 모델은 서포트 벡터 머신 (SVM)을 기반으로 하는 분류기입니다.\n",
    "SVM은 특징 공간에서 클래스 간의 최대 마진을 찾아내는 것을 목표로 합니다. 즉, 클래스를 구분하는 결정 경계를 찾는 데 초점을 맞춥니다.\n",
    "LinearSVC는 특히 텍스트 분류와 같은 고차원 데이터에 효과적으로 작동하며, 복잡한 패턴과 특징 간의 상호작용을 더 잘 포착할 수 있습니다.\n",
    "이 모델은 특히 데이터가 선형적으로 구분될 수 있을 때 강력한 성능을 발휘합니다.\n",
    "성능 차이의 이유:\n",
    "\n",
    "MultinomialNB는 간단한 확률적 접근을 사용하여 클래스를 예측하는 반면, LinearSVC는 데이터의 구조를 더 복잡하게 분석하여 클래스를 구분합니다.\n",
    "텍스트 데이터의 경우, 특히 고차원에서는 LinearSVC가 MultinomialNB보다 더 정확한 결정 경계를 찾을 가능성이 높습니다. 이는 텍스트 데이터에 내재된 복잡한 패턴과 상호 의존성을 더 잘 포착하기 때문입니다.\n",
    "LinearSVC는 일반적으로 Naive Bayes보다 더 강력한 성능을 발휘하는 경향이 있으며, 이는 데이터셋의 특성과 복잡성에 따라 달라질 수 있습니다.\n",
    "결론적으로, LinearSVC가 MultinomialNB보다 더 높은 정밀도, 재현율, F1 점수를 달성한 것은 LinearSVC가 복잡한 텍스트 데이터 패턴을 더 잘 분석하고 예측하기 때문으로 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40da71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
